{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZLRMFl0JyyQ"
      },
      "source": [
        "# **1. Perkenalan Dataset**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hssSDn-5n3HR"
      },
      "source": [
        "Tahap pertama, Anda harus mencari dan menggunakan dataset dengan ketentuan sebagai berikut:\n",
        "\n",
        "1. **Sumber Dataset**:  \n",
        "   Dataset dapat diperoleh dari berbagai sumber, seperti public repositories (*Kaggle*, *UCI ML Repository*, *Open Data*) atau data primer yang Anda kumpulkan sendiri.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **2. Import Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgA3ERnVn84N"
      },
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning atau deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start due to the missing module 'IPython'. Consider installing this module.\n",
            "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "#Type your code here\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **3. Memuat Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3ItwTen_7E"
      },
      "source": [
        "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook. Jika dataset dalam format CSV, Anda bisa menggunakan pustaka pandas untuk membacanya. Pastikan untuk mengecek beberapa baris awal dataset untuk memahami strukturnya dan memastikan data telah dimuat dengan benar.\n",
        "\n",
        "Jika dataset berada di Google Drive, pastikan Anda menghubungkan Google Drive ke Colab terlebih dahulu. Setelah dataset berhasil dimuat, langkah berikutnya adalah memeriksa kesesuaian data dan siap untuk dianalisis lebih lanjut.\n",
        "\n",
        "Jika dataset berupa unstructured data, silakan sesuaikan dengan format seperti kelas Machine Learning Pengembangan atau Machine Learning Terapan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "outputs": [],
      "source": [
        "#Type your code here\n",
        "DATA_ROOT_PATH = '../data'\n",
        "data_path = os.path.join(DATA_ROOT_PATH, 'Mobile.csv')\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgZkbJLpK9UR"
      },
      "source": [
        "# **4. Exploratory Data Analysis (EDA)**\n",
        "\n",
        "Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset.\n",
        "\n",
        "Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Pembersihan Data Terinput**\n",
        "\n",
        "Menghapus komponen teks pada setiap kolom yang seharusnya numerik. Lalu  mengubah ke tipe data yang benar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "obj_cols = df.select_dtypes(include='object')\n",
        "\n",
        "print('Kolom-kolom object:')\n",
        "obj_cols.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "col_with_digit = []\n",
        "\n",
        "for col in obj_cols:\n",
        "    # Memgambil sample data pada setiap kolom, baris pertama\n",
        "    first_row = df[col].iloc[0]\n",
        "    # Jika ditemukan data dengan nilai numerik didalamnya\n",
        "    if re.search(r'\\d+', first_row):\n",
        "        # Simpan nama col\n",
        "        col_with_digit.append(col)\n",
        "        # Maka menyisakan nilai numerik itu, dan hapus teks non numerik\n",
        "        df[col] = df[col].str.replace(r'\\D+', '', regex=True)\n",
        "    else:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hasil Pembersihan Data Terinput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[col_with_digit].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ubah Tipe Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[col_with_digit] = df[col_with_digit].astype('float64')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualisasi Distribusi Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKeejtvxM6X1"
      },
      "outputs": [],
      "source": [
        "#Type your code here\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "df[numeric_cols].hist(bins=20, figsize=(12, 8), grid=False)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_obj_cols = df.select_dtypes(include='object')\n",
        "\n",
        "# Visualisasi kolom bertipe object menggunakan bar chart dan pie chart\n",
        "for col in new_obj_cols.columns:\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    # Bar chart\n",
        "    plt.subplot(1, 2, 1)\n",
        "    df[col].value_counts().plot(kind='bar', color='skyblue')\n",
        "    plt.title(f'Bar Chart of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Pie chart\n",
        "    plt.subplot(1, 2, 2)\n",
        "    df[col].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors)\n",
        "    plt.title(f'Pie Chart of {col}')\n",
        "    plt.ylabel('')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpgHfgnSK3ip"
      },
      "source": [
        "# **5. Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COf8KUPXLg5r"
      },
      "source": [
        "Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam model machine learning.\n",
        "\n",
        "Jika Anda menggunakan data teks, data mentah sering kali mengandung nilai kosong, duplikasi, atau rentang nilai yang tidak konsisten, yang dapat memengaruhi kinerja model. Oleh karena itu, proses ini bertujuan untuk membersihkan dan mempersiapkan data agar analisis berjalan optimal.\n",
        "\n",
        "Berikut adalah tahapan-tahapan yang bisa dilakukan, tetapi **tidak terbatas** pada:\n",
        "1. Menghapus atau Menangani Data Kosong (Missing Values)\n",
        "2. Menghapus Data Duplikat\n",
        "3. Normalisasi atau Standarisasi Fitur\n",
        "4. Deteksi dan Penanganan Outlier\n",
        "5. Encoding Data Kategorikal\n",
        "6. Binning (Pengelompokan Data)\n",
        "\n",
        "Cukup sesuaikan dengan karakteristik data yang kamu gunakan yah. Khususnya ketika kami menggunakan data tidak terstruktur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Menghapus atau Menangani Data Kosong (Missing Values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og8pGV0-iDLz"
      },
      "outputs": [],
      "source": [
        "# Cek data kosong\n",
        "total_na = df.isna().sum()\n",
        "\n",
        "def delete_na(total_na, df):\n",
        "    if len(total_na) > 0:\n",
        "        df = df.dropna(axis=0)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = delete_na(total_na, df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tidak ada data kosong, maka tidak ada proses penghapusan data kosong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Menghapus Data Duplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_dups = df.duplicated().sum()\n",
        "\n",
        "def delete_dups(total_dups, df):\n",
        "    if total_dups > 0:\n",
        "        df = df.drop_duplicates(axis=0)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tidak ada data duplikat, maka tidak ada proses penghapusan data duplikasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Encoding Fitur Objek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "remain_object_cols = df.select_dtypes(include='object')\n",
        "\n",
        "for col in remain_object_cols.columns:\n",
        "    print(f\"Nilai unik Kolom {col}:\")\n",
        "    print(\"=\"*4)\n",
        "    print(df[col].unique())\n",
        "    print(\"=\"*4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Proses Encoding\n",
        "binary_cat = {'No': 0, 'Yes': 1}\n",
        "target_cat = {\"Low cost\": 0, \"Medium cost\": 1,\n",
        "              \"High cost\": 2, \"Very High cost\": 3}\n",
        "\n",
        "encoders = {'Binary_Cat': binary_cat,\n",
        "            'Target_Cat': target_cat}\n",
        "\n",
        "target_col = 'price_range'\n",
        "\n",
        "def encoding_object_feat(remain_obj_cols, target_col, all_cats):\n",
        "    for_encode_cols = remain_obj_cols.columns\n",
        "    \n",
        "    for col in for_encode_cols:\n",
        "        scaler = all_cats['Binary_Cat'] if col != target_col else all_cats['Target_Cat']\n",
        "        df[col] = df[col].map(scaler)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = encoding_object_feat(remain_object_cols, target_col, encoders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Normalisasi atau Standarisasi Fitur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cek Korelasi Fitur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix = df.corr(numeric_only=True)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=True,     \n",
        "    fmt=\".2f\",\n",
        "    cmap=\"coolwarm\",\n",
        "    center=0,\n",
        "    cbar=True\n",
        ")\n",
        "plt.title(\"Heatmap Korelasi Antar Fitur\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_target_corr = df.corr(numeric_only=True)[[target_col]].drop(index=target_col)\n",
        "feature_target_corr = feature_target_corr.sort_values(by=target_col, ascending=False)\n",
        "\n",
        "feature_target_corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Standarisasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[numeric_cols].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Standarisasi Kolom Range Spreading**\n",
        "\n",
        "Ditandai dengan standar deviasi yang lebih tinggi dari rata-rata setiap fitur yang ada. Serta korelasi yang cukup merepresentasikan hubungan dengan fitur target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "std_scaler = StandardScaler()\n",
        "\n",
        "def scale_with_std_scaler(cols, df, std_scaler):\n",
        "    df[cols] = std_scaler.fit_transform(df[cols])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "col_to_scale = ['Ram_mb', 'Battery_power_mAh', 'Pixel_width', 'px_height']\n",
        "\n",
        "df = scale_with_std_scaler(col_to_scale, df, std_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Deteksi dan Penanganan Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = df.select_dtypes(exclude='object').columns\n",
        "\n",
        "def visualize_outliers(n_cols: int = 3,\n",
        "                       figsz_x: int = 15,\n",
        "                       figsz_y: int = 5,\n",
        "                       df: pd.DataFrame = df):\n",
        "\n",
        "    n_cols = n_cols\n",
        "    n_rows = int(np.ceil(len(num_cols) / n_cols))\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(figsz_x, figsz_y * n_rows))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(num_cols):\n",
        "        sns.boxplot(y=df[col], ax=axes[i], color=\"skyblue\")\n",
        "        axes[i].set_title(f\"Outlier Check: {col}\")\n",
        "\n",
        "    # hapus subplot kosong jika jumlah kolom < n_rows*n_cols\n",
        "    for j in range(i+1, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_outliers()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_outliers_iqr(data: pd.DataFrame = df, cols: list = []) -> pd.DataFrame:\n",
        "    cleaned_data = data.copy()\n",
        "    for col in cols:\n",
        "        Q1 = cleaned_data[col].quantile(0.25)\n",
        "        Q3 = cleaned_data[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower = Q1 - 1.5 * IQR\n",
        "        upper = Q3 + 1.5 * IQR\n",
        "        cleaned_data = cleaned_data[(cleaned_data[col] >= lower) & (cleaned_data[col] <= upper)]\n",
        "    return cleaned_data\n",
        "\n",
        "df_cleaned = remove_outliers_iqr(df, num_cols)\n",
        "\n",
        "print(f\"Sebelum hapus outliers: {df.shape}\")\n",
        "print(f\"Setelah hapus outliers: {df_cleaned.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Reduksi Dimensi (Dengan LDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df_cleaned.drop(columns=[target_col])\n",
        "y = df_cleaned[target_col]\n",
        "\n",
        "def reduction_with_lda(X: pd.Series, \n",
        "                       y: pd.Series,\n",
        "                       n_comp: int = 3) -> pd.DataFrame:\n",
        "\n",
        "    lda = LinearDiscriminantAnalysis(n_components=n_comp)\n",
        "    X_lda = lda.fit_transform(X, y)\n",
        "\n",
        "    return X_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_lda = reduction_with_lda(X, y, 3)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for label in y.unique():\n",
        "    plt.scatter(\n",
        "        X_lda[y == label, 0],\n",
        "        X_lda[y == label, 1],\n",
        "        label=f\"Class {label}\",\n",
        "        alpha=0.7\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"LD1\")\n",
        "plt.ylabel(\"LD2\")\n",
        "plt.title(\"LDA: Proyeksi ke 2 Dimensi\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_splitting(X: pd.Series,\n",
        "                   y: pd.Series,\n",
        "                   rand_state: int = 42,\n",
        "                   test_size: float = 0.2) -> pd.Series:\n",
        "    X_train, y_train, X_test, y_test = train_test_split(\n",
        "        X,\n",
        "        y,\n",
        "        random_state=rand_state,\n",
        "        test_size=test_size\n",
        "    )\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test = data_splitting(X_lda, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SVC(\n",
        "    C=10,\n",
        "    gamma=0.1,\n",
        "    kernel='rbf',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predicted_qual = model.predict(X_test)\n",
        "predicted_qual"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
